{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9f0d3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:31.483621Z",
     "start_time": "2021-09-23T02:16:31.479843Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gtts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/asr-synthesis-blog/3_audio_splicing.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://notebooksa.jarvislabs.ai/home/asr-synthesis-blog/3_audio_splicing.ipynb#ch0000000vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgtts\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://notebooksa.jarvislabs.ai/home/asr-synthesis-blog/3_audio_splicing.ipynb#ch0000000vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlibrosa\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://notebooksa.jarvislabs.ai/home/asr-synthesis-blog/3_audio_splicing.ipynb#ch0000000vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gtts'"
     ]
    }
   ],
   "source": [
    "import gtts\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import srsly\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "output_dir = Path(\"./output/synth_calls/sample_transcript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da266e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_fragment_records = []\n",
    "for file in list(output_dir.glob(\"./*.mp3\")):\n",
    "    # collate utterance audio files into raw samples\n",
    "    y, s = librosa.load(str(file))  # FYI: assigns default sample rate\n",
    "    audio_fragment_records.append(\n",
    "        {\"file\": file.name, \"sample_array\": y, \"sample_array_shape\": y.shape[0]}\n",
    "    )\n",
    "\n",
    "audio_fragments = (\n",
    "    pd.DataFrame(audio_fragment_records)\n",
    "    # probably just the df index; but to be sure\n",
    "    .assign(sequence_idx=lambda x: x.file.apply(lambda y: int(y.split(\"_\")[-1][0])))\n",
    "    .sort_values(\"sequence_idx\")\n",
    "    # speaker as channel\n",
    "    .assign(channel=lambda x: x.sequence_idx.apply(lambda y: 1 if y % 2 == 0 else 2))\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a030121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# pad channel 1/2 chunks to ensure for interleaving pattern\n",
    "channel_1_segments = []\n",
    "channel_2_segments = []\n",
    "for idx, e in audio_fragments.iterrows():\n",
    "\n",
    "    if e.channel == 1:\n",
    "        channel_1_segments.append(e.sample_array)\n",
    "        # pad alternating channel (channel 2) with equivalent size zero array to create interleave\n",
    "        channel_2_segments.append(np.zeros(e.sample_array.shape[0], dtype=np.float32))\n",
    "    else:\n",
    "        # odd indices are channel 2\n",
    "        channel_2_segments.append(e.sample_array)\n",
    "        # otherwise, channel 2 length zero array\n",
    "        channel_1_segments.append(np.zeros(e.sample_array.shape[0], dtype=np.float32))\n",
    "\n",
    "# temp save for channel 1/2 audio - saves as mono\n",
    "default_sr = 22050\n",
    "channel_1_padded = np.concatenate(channel_1_segments)\n",
    "soundfile.write(output_dir / \"channel_1_temp.wav\", channel_1_padded, default_sr)\n",
    "\n",
    "channel_2_padded = np.concatenate(channel_2_segments)\n",
    "soundfile.write(output_dir / \"channel_2_temp.wav\", channel_2_padded, default_sr)\n",
    "\n",
    "# consolidate into an interleaving, channel seperated source\n",
    "left_channel = AudioSegment.from_wav(output_dir / \"channel_1_temp.wav\")\n",
    "right_channel = AudioSegment.from_wav(output_dir / \"channel_2_temp.wav\")\n",
    "\n",
    "stereo_sound = AudioSegment.from_mono_audiosegments(left_channel, right_channel)\n",
    "stereo_sound.export(output_dir / \"consolidated_final.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16dc95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:30:24.359783Z",
     "start_time": "2021-09-23T02:30:24.348606Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_episode(episode_raw):\n",
    "    # as a dataframe\n",
    "    episode = []\n",
    "    for e in episode_raw[\"dialog\"]:\n",
    "        episode.extend([{\"id\": ee[\"id\"], \"text\": ee[\"text\"]} for ee in e])\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame(episode)\n",
    "        .reset_index()\n",
    "        .rename(mapper={\"index\": \"exchange_index\"}, axis=\"columns\")\n",
    "        .assign(speaker=lambda x: x.id.apply(lambda y: int(y.split(\"_\")[1])))\n",
    "    )\n",
    "\n",
    "\n",
    "def synthesize_tts_episode(episode_df, output_dir):\n",
    "    # given an episode DF, synthesize audio for each utterance\n",
    "    for idx, e in episode_df.iterrows():\n",
    "        time.sleep(1)  # prevent IP banning?\n",
    "        # format text/save file\n",
    "        save_path = output_dir / f\"{e.exchange_index}_speaker_{e.speaker}.mp3\"\n",
    "\n",
    "        # alternative voices, useful for debugging, could be improved with more variance\n",
    "        if e.speaker == 1:\n",
    "            tts = gtts.gTTS(e.text, lang=\"en\", tld=\"com\", slow=True)\n",
    "        elif e.speaker == 2:\n",
    "            tts = gtts.gTTS(e.text, lang=\"en\", tld=\"ca\", slow=True)\n",
    "\n",
    "        tts.save(save_path)\n",
    "\n",
    "\n",
    "def get_utterance_df(output_dir):\n",
    "    # DF with utterance audio arrays + useful metadata\n",
    "    audio_file_records = []\n",
    "    for e in sorted(list(output_dir.rglob(\"./*.mp3\"))):\n",
    "        y, s = librosa.load(e.as_posix())  # new downsample rate\n",
    "        audio_file_records.append(\n",
    "            {\"file\": e.name, \"sample_array\": y, \"sample_array_shape\": y.shape[0]}\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame(audio_file_records)\n",
    "        .sort_values(\"file\")\n",
    "        .assign(channel=lambda x: x.file.apply(lambda y: int(y.split(\"_\")[-1][0])))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def pad_and_collate_channel_audio(utterance_df, output_dir):\n",
    "    # pad channel 1/2 chunks to ensure for interleaving pattern, isolate across seperate channels\n",
    "    channel_1_segments = []\n",
    "    channel_2_segments = []\n",
    "    for idx, e in utterance_df.iterrows():\n",
    "        if idx % 2 == 0:\n",
    "            print(f\"{e.file} is even\")\n",
    "            # even indices are channel 1; starting first, indexing from zero\n",
    "            channel_1_segments.append(e.sample_array)  # the actual samples\n",
    "            # pad alternating channel (channel 2) with equivalent size zero array\n",
    "            channel_2_segments.append(\n",
    "                np.zeros(e.sample_array.shape[0], dtype=np.float32)\n",
    "            )\n",
    "        else:\n",
    "            print(f\"{e.file} is odd\")\n",
    "            # odd indices are channel 2\n",
    "            channel_2_segments.append(e.sample_array)\n",
    "            # otherwise, channel 2 length zero array\n",
    "            channel_1_segments.append(\n",
    "                np.zeros(e.sample_array.shape[0], dtype=np.float32)\n",
    "            )\n",
    "\n",
    "    # temp save for channel 1/2 audio - saves as mono\n",
    "    default_sr = 22050\n",
    "    channel_1_padded = np.concatenate(channel_1_segments)\n",
    "    soundfile.write(output_dir / \"channel_1_temp.wav\", channel_1_padded, default_sr)\n",
    "\n",
    "    channel_2_padded = np.concatenate(channel_2_segments)\n",
    "    soundfile.write(output_dir / \"channel_2_temp.wav\", channel_2_padded, default_sr)\n",
    "\n",
    "\n",
    "def collate_channel_audio(output_dir):\n",
    "    # consolidate into an interleaving, channel seperated source\n",
    "    left_channel = AudioSegment.from_wav(output_dir / \"channel_1_temp.wav\")\n",
    "    right_channel = AudioSegment.from_wav(output_dir / \"channel_2_temp.wav\")\n",
    "\n",
    "    # load individual channels...\n",
    "    stereo_sound = AudioSegment.from_mono_audiosegments(left_channel, right_channel)\n",
    "    stereo_sound.export(output_dir / f\"{output_dir.name}_final.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5306d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:38.584351Z",
     "start_time": "2021-09-23T02:16:38.441881Z"
    }
   },
   "outputs": [],
   "source": [
    "base_output_dir = Path(\"/path/to/synthesis\")\n",
    "# a collection of self-chat episodes\n",
    "self_chat = list(srsly.read_jsonl(\"/path/to/self/chat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5c31d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:30:48.919573Z",
     "start_time": "2021-09-23T02:30:28.431217Z"
    }
   },
   "outputs": [],
   "source": [
    "# for episode in self_chat:\n",
    "episode = self_chat[0]\n",
    "# format episode\n",
    "episode = format_episode(episode).head(8)\n",
    "\n",
    "# create unique output dir\n",
    "episode_id = uuid4().hex\n",
    "output_dir = base_output_dir / episode_id\n",
    "output_dir.mkdir(exist_ok=True, parents=True) if output_dir.exists() == False else None\n",
    "\n",
    "# synthesize, save audio\n",
    "synthesize_tts_episode(episode, output_dir)\n",
    "\n",
    "# retrieve raw audio amplitude arrays\n",
    "utterance_df = get_utterance_df(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac3403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:38:45.297282Z",
     "start_time": "2021-09-23T02:38:44.617322Z"
    }
   },
   "outputs": [],
   "source": [
    "# collate/pad/save into channel-specific wav files\n",
    "pad_and_collate_channel_audio(utterance_df, output_dir)\n",
    "\n",
    "# consolidate into final file\n",
    "collate_channel_audio(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20aaac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T00:51:46.399547Z",
     "start_time": "2021-09-23T00:51:46.397128Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccfb2f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T00:54:15.115726Z",
     "start_time": "2021-09-23T00:54:14.857286Z"
    }
   },
   "outputs": [],
   "source": [
    "channel_1 = AudioSegment.from_file(\n",
    "    \"/home/samhardyhey/dir/experiment_artefacts/stt_adjacent_processing/synthesis/28f812fb47584582b864b7655859ead1/channel_1_temp.wav\"\n",
    ")\n",
    "channel_2 = AudioSegment.from_file(\n",
    "    \"/home/samhardyhey/dir/experiment_artefacts/stt_adjacent_processing/synthesis/28f812fb47584582b864b7655859ead1/channel_2_temp.wav\"\n",
    ")\n",
    "merged = AudioSegment.from_file(\n",
    "    \"/home/samhardyhey/dir/experiment_artefacts/stt_adjacent_processing/synthesis/28f812fb47584582b864b7655859ead1/28f812fb47584582b864b7655859ead1_final.wav\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b82607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the final wavs in a single dir\n",
    "episode_wav_dir = base_output_dir / \"episode_wavs\"\n",
    "episode_wav_dir.mkdir(\n",
    "    exist_ok=True, parents=True\n",
    ") if episode_wav_dir.exists() == False else None\n",
    "\n",
    "for e in list(base_output_dir.rglob(\"./*.wav\")):\n",
    "    if \"final\" in e.as_posix():\n",
    "        shutil.move(e.as_posix(), (episode_wav_dir / e.name).as_posix())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d4ab08",
   "metadata": {},
   "source": [
    "## Potentially experiment with different TLD for different voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    ".google.com .google.ad .google.ae .google.com.af .google.com.ag .google.com.ai .google.al .google.am .google.co.ao .google.com.ar .google.as .google.at .google.com.au .google.az .google.ba .google.com.bd .google.be .google.bf .google.bg .google.com.bh .google.bi .google.bj .google.com.bn .google.com.bo .google.com.br .google.bs .google.bt .google.co.bw .google.by .google.com.bz .google.ca .google.cd .google.cf .google.cg .google.ch .google.ci .google.co.ck .google.cl .google.cm .google.cn .google.com.co .google.co.cr .google.com.cu .google.cv .google.com.cy .google.cz .google.de .google.dj .google.dk .google.dm .google.com.do .google.dz .google.com.ec .google.ee .google.com.eg .google.es .google.com.et .google.fi .google.com.fj .google.fm .google.fr .google.ga .google.ge .google.gg .google.com.gh .google.com.gi .google.gl .google.gm .google.gr .google.com.gt .google.gy .google.com.hk .google.hn .google.hr .google.ht .google.hu .google.co.id .google.ie .google.co.il .google.im .google.co.in .google.iq .google.is .google.it .google.je .google.com.jm .google.jo .google.co.jp .google.co.ke .google.com.kh .google.ki .google.kg .google.co.kr .google.com.kw .google.kz .google.la .google.com.lb .google.li .google.lk .google.co.ls .google.lt .google.lu .google.lv .google.com.ly .google.co.ma .google.md .google.me .google.mg .google.mk .google.ml .google.com.mm .google.mn .google.ms .google.com.mt .google.mu .google.mv .google.mw .google.com.mx .google.com.my .google.co.mz .google.com.na .google.com.ng .google.com.ni .google.ne .google.nl .google.no .google.com.np .google.nr .google.nu .google.co.nz .google.com.om .google.com.pa .google.com.pe .google.com.pg .google.com.ph .google.com.pk .google.pl .google.pn .google.com.pr .google.ps .google.pt .google.com.py .google.com.qa .google.ro .google.ru .google.rw .google.com.sa .google.com.sb .google.sc .google.se .google.com.sg .google.sh .google.si .google.sk .google.com.sl .google.sn .google.so .google.sm .google.sr .google.st .google.com.sv .google.td .google.tg .google.co.th .google.com.tj .google.tl .google.tm .google.tn .google.to .google.com.tr .google.tt .google.com.tw .google.co.tz .google.com.ua .google.co.ug .google.co.uk .google.com.uy .google.co.uz .google.com.vc .google.co.ve .google.vg .google.co.vi .google.com.vn .google.vu .google.ws .google.rs .google.co.za .google.co.zm .google.co.zw .google.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = gtts.gTTS(e.text, lang=\"en\", tld=\"com\", slow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if e.speaker == 1:\n",
    "    tts = gtts.gTTS(e.text, lang=\"en\", tld=\"com\", slow=True)\n",
    "elif e.speaker == 2:\n",
    "    tts = gtts.gTTS(e.text, lang=\"en\", tld=\"ca\", slow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd04c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:32:41.668463Z",
     "start_time": "2021-09-23T02:32:40.433119Z"
    }
   },
   "outputs": [],
   "source": [
    "import gtts\n",
    "\n",
    "tts = gtts.gTTS(\"hello world my name is Sam\", lang=\"en\", tld=\"com\", slow=True)\n",
    "tts.save(\"./temp_audio.mp3\")\n",
    "AudioSegment.from_file(\"./temp_audio.mp3\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('blog.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b352da5c727154a09156c935f17a9c4d49b2c9c0946f47ddfcca219f38b45087"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
